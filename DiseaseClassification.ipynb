{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinal Disease Detection and Classification\n",
    "\n",
    "## By: Jalen Wu, Yechan Na, Jonathan Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Project Description:__\n",
    "\n",
    "The goal of this project is to develop a machine learning model capable of detecting retinal diseases by analyzing fundus images of the eye. Using computer vision and deep learning techniques, the model assists in early detection and diagnosis of retinal disease(s).\n",
    "\n",
    "__Applications and Impact:__\n",
    "\n",
    "This project could be used for clinical screening to help ophthalmologists identify diseases and improve efficiency on identifying these diseases. This automated detection system has the potential to make medical imaging diagnostics more accessible.\n",
    "\n",
    "__What we hope to achieve:__\n",
    "\n",
    "We hope to build a model that takes in images of the eye and accurately predicts whether an individual’s eyes are healthy or showing signs of disease. To quantify the effectiveness of our model, we will be measuring metrics such as F1 score, precision, recall, loss, and accuracy of our models and graphing them as a function of how many epochs we run on our training data (all of these scores should increase in subsequent epochs).\n",
    "\n",
    "- __Dataset__: https://www.kaggle.com/datasets/andrewmvd/retinal-disease-classification/data\n",
    "- __References__: \n",
    "    - https://www.mdpi.com/2306-5729/6/2/14\n",
    "    - https://jamanetwork.com/journals/jama/fullarticle/2588763\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torch import tensor\n",
    "from PIL import Image\n",
    "from torch import flatten\n",
    "from nltk.metrics.scores import (precision, recall, f_measure, accuracy)\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/jalenwu/.cache/kagglehub/datasets/andrewmvd/retinal-disease-classification/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewmvd/retinal-disease-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jalenwu/.cache/kagglehub/datasets/andrewmvd/retinal-disease-classification/versions/1\n",
      "Directory exists and its contents are:\n",
      "['.DS_Store', 'Evaluation_Set', 'Training_Set', 'Test_Set']\n"
     ]
    }
   ],
   "source": [
    "# X = 1424 x 2144 x 3 : h x w x colors\n",
    "# y = label\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((int(1424 / 8), int(2144 / 8))), # Standardize image dimensions\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "base_directory = path  \n",
    "print(base_directory)\n",
    "\n",
    "if os.path.exists(base_directory):\n",
    "    print(\"Directory exists and its contents are:\")\n",
    "    print(os.listdir(base_directory))\n",
    "else:\n",
    "    print(\"Directory does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (paths that will be accessed later in the project)\n",
    "BASE_DIRECTORY = path\n",
    "TRAINING_DIRECTORY = os.path.join(BASE_DIRECTORY, 'Training_Set', 'Training_Set', 'Training')\n",
    "TRAINING_LABELS = os.path.join(BASE_DIRECTORY, 'Training_Set', 'Training_Set', 'RFMiD_Training_Labels.csv')\n",
    "TESTING_DIRECTORY = os.path.join(BASE_DIRECTORY, 'Test_Set', 'Test_Set', 'Test')\n",
    "TESTING_LABELS = os.path.join(BASE_DIRECTORY, 'Test_Set', 'Test_Set', 'RFMiD_Testing_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delegated the dataframe creation outside of the dataset class\n",
    "training_labels_df = pd.read_csv(TRAINING_LABELS)\n",
    "testing_labels_df = pd.read_csv(TESTING_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sorting the diseases by count and extracting the top 5.\n",
    "\n",
    "# disease_counts = defaultdict(int)\n",
    "# column_names = list(training_labels_df.columns)\n",
    "\n",
    "# for column in column_names:\n",
    "#     if column != 'ID' and column != 'Disease_Risk':\n",
    "#         disease_counts[column] = training_labels_df[column].sum()\n",
    "    \n",
    "# sorted_disease_counts = sorted(disease_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "# keep_diseases = ['Disease_Risk']\n",
    "# for i in range(5):\n",
    "#     keep_diseases.append(sorted_disease_counts[i][0])\n",
    "\n",
    "# print(keep_diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_labels_df = training_labels_df.filter(keep_diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Disease_Risk</th>\n",
       "      <th>DR</th>\n",
       "      <th>ARMD</th>\n",
       "      <th>MH</th>\n",
       "      <th>DN</th>\n",
       "      <th>MYA</th>\n",
       "      <th>BRVO</th>\n",
       "      <th>TSLN</th>\n",
       "      <th>ERM</th>\n",
       "      <th>...</th>\n",
       "      <th>CME</th>\n",
       "      <th>PTCR</th>\n",
       "      <th>CF</th>\n",
       "      <th>VH</th>\n",
       "      <th>MCA</th>\n",
       "      <th>VS</th>\n",
       "      <th>BRAO</th>\n",
       "      <th>PLQ</th>\n",
       "      <th>HPED</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Disease_Risk  DR  ARMD  MH  DN  MYA  BRVO  TSLN  ERM  ...  CME  PTCR  \\\n",
       "0   1             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "1   2             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "2   3             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "3   4             1   0     0   1   0    0     0     0    0  ...    0     0   \n",
       "4   5             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "\n",
       "   CF  VH  MCA  VS  BRAO  PLQ  HPED  CL  \n",
       "0   0   0    0   0     0    0     0   0  \n",
       "1   0   0    0   0     0    0     0   0  \n",
       "2   0   0    0   0     0    0     0   0  \n",
       "3   0   0    0   0     0    0     0   0  \n",
       "4   0   0    0   0     0    0     0   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Disease_Risk\n",
       "0             1\n",
       "1             1\n",
       "2             1\n",
       "3             1\n",
       "4             1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels_df = training_labels_df.filter(['Disease_Risk'])\n",
    "testing_labels_df = testing_labels_df.filter(['Disease_Risk'])\n",
    "training_labels_df.head()\n",
    "# testing_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Supports structure of given dataset (images in child folder and labels in csv format).\n",
    "    \"\"\"\n",
    "    def __init__(self, label_csv_file, image_directory, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_csv_file (DataFrame): Dataframe of the CSV label file.\n",
    "            image_directory (str): Directory with eye images.\n",
    "            transform (callable, optional): transform function to be applied to each image.\n",
    "        \"\"\"\n",
    "        self.label_csv_file = label_csv_file\n",
    "        self.image_directory = image_directory\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_csv_file)    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of the image/label pair we want to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            image_and_label (dict): A dictionary containing the image and its corresponding label at the requested index.\n",
    "        \"\"\"\n",
    "\n",
    "        # The images are PNG and one-indexed (1.png, 2.png, 3.png, ...)\n",
    "        image_path = os.path.join(self.image_directory, str(index + 1) +'.png')\n",
    "        \n",
    "        image_label = self.label_csv_file.loc[index]\n",
    "        image_label = image_label.to_numpy()\n",
    "        image_label = tensor(image_label)\n",
    "        \n",
    "        # Loads image at the given path.\n",
    "        current_image = io.imread(image_path)\n",
    "        \n",
    "        if current_image is None or current_image.size == 0:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "       \n",
    "        # Convert to PIL Image\n",
    "        current_image = Image.fromarray(current_image)\n",
    "        \n",
    "        # If transform function passed in, apply transform to image\n",
    "        if self.transform:\n",
    "            transformed_image = self.transform(current_image)\n",
    "            return {'image': transformed_image, 'label': image_label}\n",
    "        \n",
    "        return {'image': current_image,'label': image_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing dataset and loader.\n",
    "train_dataset = MultiClassDataset(label_csv_file=training_labels_df, image_directory=TRAINING_DIRECTORY, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "# Visualize loader\n",
    "res = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 178, 268])\n",
      "torch.Size([64, 1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(res['image'].shape)\n",
    "print(res['label'].shape)\n",
    "\n",
    "print(res['label'][0])\n",
    "print(res['label'][1])\n",
    "print(res['label'][2])\n",
    "print(res['label'][3])\n",
    "print(res['image'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 178, 268])\n"
     ]
    }
   ],
   "source": [
    "# image tensor format: [batch_size, channels, height, width]\n",
    "print(res['image'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Network\n",
    "class Conv_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(8640, 256)\n",
    "        self.fc2 = nn.Linear(256, 120)\n",
    "        self.fc3 = nn.Linear(120, 84)\n",
    "        self.fc4 = nn.Linear(84, 23)\n",
    "        self.fc5 = nn.Linear(23, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.sigmoid(self.fc5(x))\n",
    "        return x\n",
    "\n",
    "conv_model = Conv_NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    total_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        # get the inputs; data is a dict of [inputs, labels]\n",
    "        inputs = data['image']\n",
    "        labels = data['label']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MultiClassDataset(label_csv_file=testing_labels_df, image_directory=TESTING_DIRECTORY, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRFA(predictions, answers):\n",
    "    pred_indices = [x for x in range(len(predictions)) if predictions[x] == 1]\n",
    "    labelabel_indexndices = [y for y in range(len(answers)) if answers[y] == 1]\n",
    "\n",
    "    temp_precision = precision(set(pred_indices), set(labelabel_indexndices)) # actual labels vs. predicted labels\n",
    "    temp_recall = recall(set(pred_indices), set(labelabel_indexndices))\n",
    "    temp_f1 = f_measure(set(pred_indices), set(labelabel_indexndices))\n",
    "    temp_accuracy = accuracy(answers, predictions)\n",
    "    return (temp_precision, temp_recall, temp_f1, temp_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_values = []\n",
    "\n",
    "def get_preds(dataloader, model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader)):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['image']\n",
    "            l = data['label']\n",
    "            \n",
    "            labels.append(l)\n",
    "            preds.append(model(inputs))\n",
    "    return torch.cat(preds), torch.cat(labels)\n",
    "\n",
    "\n",
    "def get_clamped_preds(preds, t):\n",
    "    \"\"\"\n",
    "    Takes a dataloader for the test data and model\n",
    "    Returns the Precision, Recall, F1 Score, and Accuracy of the model as a tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    new_preds = torch.tensor(np.zeros([len(preds)], dtype=int))\n",
    "    # Goes through all images in preds\n",
    "    for img_in_batch in range(len(preds)): \n",
    "        # Goes through all disease labels in the image\n",
    "        # Clamp the values to 0 or 1\n",
    "        if preds[img_in_batch] > t:\n",
    "            new_preds[img_in_batch] = 1\n",
    "        else:\n",
    "            new_preds[img_in_batch] = 0\n",
    "    return new_preds\n",
    "\n",
    "\n",
    "def test(new_preds, labels):\n",
    "    size = len(new_preds)\n",
    "    correct = 0\n",
    "    for i in range(len(new_preds)):\n",
    "        if new_preds[i] == labels[i]:\n",
    "            #print(new_preds[i])\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / size\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    #return accuracy\n",
    "    return PRFA(new_preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Changed learning rate from 0.001 to 0.01\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# optimizer = optim.Adam(conv_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [05:51, 11.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Model Loss:  0.010009087746342023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:57, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5646])\n",
      "tensor(0)\n",
      "Accuracy:  0.24375\n",
      "prfa: \n",
      "0.1442687747035573 0.5887096774193549 0.23174603174603176 tensor([0.2438])\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [06:27, 12.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Model Loss:  0.009675264358520508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:01, 12.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5863])\n",
      "tensor(1)\n",
      "Accuracy:  0.3484375\n",
      "prfa: \n",
      "0.2608695652173913 0.7542857142857143 0.3876651982378855 tensor([0.3484])\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [06:18, 12.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Model Loss:  0.00939668423185746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:02, 12.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6061])\n",
      "tensor(1)\n",
      "Accuracy:  0.525\n",
      "prfa: \n",
      "0.49209486166007904 0.8412162162162162 0.6209476309226932 tensor([0.5250])\n",
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [06:07, 12.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Model Loss:  0.009164644467333952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:14, 13.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6240])\n",
      "tensor(1)\n",
      "Accuracy:  0.5796875\n",
      "prfa: \n",
      "0.5632411067193676 0.8558558558558559 0.6793802145411204 tensor([0.5797])\n",
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [06:22, 12.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Model Loss:  0.008971048410361011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:06, 12.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6401])\n",
      "tensor(1)\n",
      "Accuracy:  0.6078125\n",
      "prfa: \n",
      "0.5810276679841897 0.8828828828828829 0.7008343265792609 tensor([0.6078])\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [06:20, 12.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Model Loss:  0.00881068113570412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:12, 13.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6546])\n",
      "tensor(1)\n",
      "Accuracy:  0.621875\n",
      "prfa: \n",
      "0.5731225296442688 0.9177215189873418 0.7055961070559612 tensor([0.6219])\n",
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [06:42, 13.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Model Loss:  0.00867738484715422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:00, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6678])\n",
      "tensor(1)\n",
      "Accuracy:  0.6140625\n",
      "prfa: \n",
      "0.5652173913043478 0.9137380191693291 0.6984126984126984 tensor([0.6141])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "conv_model_loss = []\n",
    "p_scores = []\n",
    "r_scores = []\n",
    "f_scores = []\n",
    "a_scores = []\n",
    "\n",
    "#conv_model = Conv_NN()\n",
    "#conv_model.load_state_dict(torch.load(\"5th_conv_model.pth\", weights_only=True))\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    conv_loss = train(train_loader, conv_model, loss_fn, optimizer)\n",
    "    print(\"Convolutional Model Loss: \", conv_loss)\n",
    "    \n",
    "    if t > 3 and conv_loss > conv_model_loss[-1]:\n",
    "        break\n",
    "        \n",
    "    preds, labels = get_preds(test_loader, conv_model)\n",
    "    avg = (max(preds) + min(preds)) / 2\n",
    "    print(avg)\n",
    "    new_preds = get_clamped_preds(torch.flatten(preds), avg)\n",
    "    print(new_preds[0])\n",
    "    p, r, f, a = test(new_preds, labels)\n",
    "    \n",
    "    print(\"prfa: \")\n",
    "    print(p, r, f, a)\n",
    "    p_scores.append(p)\n",
    "    r_scores.append(r)\n",
    "    f_scores.append(f)\n",
    "    a_scores.append(a)\n",
    "    \n",
    "     # if the accuracy has decreased, early stop\n",
    "    if len(a_scores) > 1 and a_scores[-1] < a_scores[-2]:\n",
    "        break\n",
    "    \n",
    "    conv_model_loss.append(conv_loss)\n",
    "    torch.save(conv_model.state_dict(), \"binary_model.pth\")\n",
    "\n",
    "\n",
    "    file = open(\"Convolutional_model_scores.txt\", \"w\", encoding=\"utf8\")\n",
    "    file.write(f\"losses: {conv_model_loss} \\n\")\n",
    "    file.write(f\"precisions: {p_scores} \\n\")\n",
    "    file.write(f\"recalls: {r_scores} \\n\")\n",
    "    file.write(f\"f1 scores: {f_scores} \\n\")\n",
    "    file.write(f\"accuracies: {a_scores} \\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- Plot loss/accuracy (y) with number of epochs ran (x)\n",
    "- Recall/Precision/F1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Conv_NN()\n",
    "conv_model.load_state_dict(torch.load(\"5th_conv_model.pth\", weights_only=True))\n",
    "\n",
    "test(test_loader, conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loss(x, y, metric):\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"epoch #\")\n",
    "    plt.ylabel(f\"{metric} score per epoch\")\n",
    "    plt.title(f\"{metric} Scores\")\n",
    "    plt.savefig(f\"{metric}_plot.png\")\n",
    "    plt.clf()\n",
    "\n",
    "graph_loss(range(len(conv_model_loss)), conv_model_loss, \"Cross Entropy Loss\")\n",
    "graph_loss(range(len(p_scores)), p_scores, \"Precision\")\n",
    "graph_loss(range(len(r_scores)), r_scores, \"Recall\")\n",
    "graph_loss(range(len(f_scores)), f_scores, \"F1\")\n",
    "graph_loss(range(len(a_scores)), a_scores, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First vs Final Scores:\")\n",
    "print(\"Cross Entropy Loss:\", conv_model_loss[0], conv_model_loss[-1])\n",
    "print(\"Precision:\", p_scores[0], p_scores[-1])\n",
    "print(\"Recall:\", r_scores[0], r_scores[-1])\n",
    "print(\"F1:\", f_scores[0], f_scores[-1])\n",
    "print(\"Accuracy:\", float(a_scores[0]), float(a_scores[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(images[0])\n",
    "# print labels\n",
    "print(classes[labels[0]], images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
